# ğŸ–ï¸ Real-Time Sign Language Detection
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A real-time sign language recognition system built using **YOLOv5**, designed to detect and classify hand gestures into meaningful text. This project aims to bridge communication gaps by recognizing American Sign Language (ASL) gestures from video streams with high accuracy.

---



## ğŸ“– Table of Contents
- [ğŸš€ What This Project Does](#-what-this-project-does)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸ”§ Installation & Setup](#-installation--setup)
- [ğŸ’¡ Usage](#-usage)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“œ License](#-license)
- [ğŸ”— Important Links](#-important-links)
- [ğŸ“ Footer](#-footer)

---



## ğŸš€ What This Project Does
- âœ… Uses **YOLOv5 object detection** to detect hand gestures in live video
- âœ… Classifies gestures based on a custom-trained dataset
- âœ… Outputs predicted gestures in real time, converting sign language into readable text
- âœ… Designed for accessibility applications, particularly for the deaf and hard-of-hearing community

---



## ğŸ› ï¸ Tech Stack
- **Language:** Python 3
- **Model:** YOLOv5 (Ultralytics)
- **Libraries:** OpenCV, PyTorch, NumPy
- **Interface:** Jupyter Notebook / Python script
- **Model Source:** Trained on ASL dataset

---



## ğŸ”§ Installation & Setup
Clone this repository:

```bash
git clone https://github.com/arorakrishh/sign-language-detector.git
cd sign-language-detector
```

---



## ğŸ’¡ Usage
1.  **Data Collection**: Utilize `data-collection.ipynb` to gather and prepare your ASL dataset.
2.  **Model Training**: Leverage the YOLOv5 framework with the provided configurations (`data.yaml`, `hyp.yaml`, `opt.yaml`) to train a custom sign language detection model.
3.  **Real-time Detection**: Deploy the trained model to process video streams and convert sign language gestures into readable text in real-time.

**Real-World Use Cases:**

*   **Accessibility Tools**: Develop assistive technologies for individuals who are deaf or hard-of-hearing, enabling communication through sign language recognition.
*   **Educational Resources**: Create interactive learning platforms for teaching and practicing sign language.
*   **Communication Aids**: Integrate sign language detection into communication devices to facilitate interaction between sign language users and others.

To use the project, follow these steps:

1.  Ensure you have the necessary libraries installed (OpenCV, PyTorch, NumPy).
2.  Run the `data-collection.ipynb` notebook to collect or prepare your dataset.
3.  Train the YOLOv5 model using your dataset and the provided configuration files.
4.  Deploy the trained model in a Python script or Jupyter Notebook for real-time sign language detection.

---



## ğŸ“ Project Structure
```
Sign-Language-Detector/
â”œâ”€â”€ README.md
â”œâ”€â”€ data-collection.ipynb
â”œâ”€â”€ data.yaml
â”œâ”€â”€ labels.csv
â””â”€â”€ result/
    â”œâ”€â”€ hyp.yaml
    â”œâ”€â”€ opt.yaml
    â””â”€â”€ results.csv
```

**Description of Files:**

*   `README.md`: Project documentation providing an overview of the project, setup instructions, and usage guidelines.
*   `data-collection.ipynb`: Jupyter Notebook for collecting and preparing the ASL dataset.
*   `data.yaml`: YAML configuration file for specifying dataset parameters.
*   `labels.csv`: CSV file containing labels for the sign language gestures.
*   `result/hyp.yaml`: YAML configuration file containing hyperparameter settings for training the YOLOv5 model.
*   `result/opt.yaml`: YAML configuration file containing optimized settings for the YOLOv5 model.
*   `result/results.csv`: CSV file containing the results of the YOLOv5 model training.

---



## ğŸ¤ Contributing
Contributions are welcome! Please follow these steps:

1.  Fork the repository.
2.  Create a new branch for your feature or bug fix.
3.  Make your changes and commit them with descriptive messages.
4.  Submit a pull request.

---



## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](https://opensource.org/licenses/MIT) file for details.

---



## ğŸ”— Important Links
*   **Repository Link**: [Sign-Language-Detector](https://github.com/arorakrishh/Sign-Language-Detector)
*   **Author's Profile**: [arorakrishh](https://github.com/arorakrishh)

---



## ğŸ“ Footer
Sign-Language-Detector, [https://github.com/arorakrishh/Sign-Language-Detector](https://github.com/arorakrishh/Sign-Language-Detector)

**Author**: arorakrishh

Feel free to fork, like, star, and raise issues!


