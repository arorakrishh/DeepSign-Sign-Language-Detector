# ğŸ–ï¸ Real-Time Sign Language Detection

A real-time sign language recognition system built using **YOLOv5**, designed to detect and classify hand gestures into meaningful text. This project aims to bridge communication gaps by recognizing American Sign Language (ASL) gestures from video streams with high accuracy.

---

## ğŸš€ What This Project Does

- Uses **YOLOv5 object detection** to detect hand gestures in live video
- Classifies gestures based on a custom-trained dataset
- Outputs predicted gestures in real time, converting sign language into readable text
- Designed for accessibility applications, particularly for the deaf and hard-of-hearing community

---


## ğŸ› ï¸ Tech Stack

- **Language:** Python 3
- **Model:** YOLOv5 (Ultralytics)
- **Libraries:** OpenCV, PyTorch, NumPy
- **Interface:** Jupyter Notebook / Python script
- **Model Source:** Trained on ASL dataset

---

## ğŸ”§ Installation & Setup

 Clone this repository:
   ```bash
   git clone https://github.com/arorakrishh/sign-language-detector.git
   cd sign-language-detector
